{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On my honor, as a student, I have neither given nor received unauthorized aid on this academic work.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.0\n"
     ]
    }
   ],
   "source": [
    "# Below is the version of Gensim (Python package for Topic Modeling) I am using in this example\n",
    "import gensim\n",
    "print gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import ldamodel\n",
    "import numpy\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # To ignore all warnings that arise here to enhance clarity\n",
    "# import packages for text processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>ord_in_thread</th>\n",
       "      <th>author</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>crawled</th>\n",
       "      <th>site_url</th>\n",
       "      <th>country</th>\n",
       "      <th>domain_rank</th>\n",
       "      <th>thread_title</th>\n",
       "      <th>spam_score</th>\n",
       "      <th>main_img_url</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>participants_count</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>shares</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6a175f46bcd24d39b3e962ad0f29936721db70db</td>\n",
       "      <td>0</td>\n",
       "      <td>Barracuda Brigade</td>\n",
       "      <td>2016-10-26T21:41:00.000+03:00</td>\n",
       "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
       "      <td>Print They should pay all the back all the mon...</td>\n",
       "      <td>english</td>\n",
       "      <td>2016-10-27T01:49:27.168+03:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>US</td>\n",
       "      <td>25689.0</td>\n",
       "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2bdc29d12605ef9cf3f09f9875040a7113be5d5b</td>\n",
       "      <td>0</td>\n",
       "      <td>reasoning with facts</td>\n",
       "      <td>2016-10-29T08:47:11.259+03:00</td>\n",
       "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
       "      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n",
       "      <td>english</td>\n",
       "      <td>2016-10-29T08:47:11.259+03:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>US</td>\n",
       "      <td>25689.0</td>\n",
       "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c70e149fdd53de5e61c29281100b9de0ed268bc3</td>\n",
       "      <td>0</td>\n",
       "      <td>Barracuda Brigade</td>\n",
       "      <td>2016-10-31T01:41:49.479+02:00</td>\n",
       "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
       "      <td>Red State : \\nFox News Sunday reported this mo...</td>\n",
       "      <td>english</td>\n",
       "      <td>2016-10-31T01:41:49.479+02:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>US</td>\n",
       "      <td>25689.0</td>\n",
       "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7cf7c15731ac2a116dd7f629bd57ea468ed70284</td>\n",
       "      <td>0</td>\n",
       "      <td>Fed Up</td>\n",
       "      <td>2016-11-01T05:22:00.000+02:00</td>\n",
       "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
       "      <td>Email Kayla Mueller was a prisoner and torture...</td>\n",
       "      <td>english</td>\n",
       "      <td>2016-11-01T15:46:26.304+02:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>US</td>\n",
       "      <td>25689.0</td>\n",
       "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
       "      <td>0.068</td>\n",
       "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0206b54719c7e241ffe0ad4315b808290dbe6c0f</td>\n",
       "      <td>0</td>\n",
       "      <td>Fed Up</td>\n",
       "      <td>2016-11-01T21:56:00.000+02:00</td>\n",
       "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
       "      <td>Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...</td>\n",
       "      <td>english</td>\n",
       "      <td>2016-11-01T23:59:42.266+02:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>US</td>\n",
       "      <td>25689.0</td>\n",
       "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
       "      <td>0.865</td>\n",
       "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       uuid  ord_in_thread  \\\n",
       "0  6a175f46bcd24d39b3e962ad0f29936721db70db              0   \n",
       "1  2bdc29d12605ef9cf3f09f9875040a7113be5d5b              0   \n",
       "2  c70e149fdd53de5e61c29281100b9de0ed268bc3              0   \n",
       "3  7cf7c15731ac2a116dd7f629bd57ea468ed70284              0   \n",
       "4  0206b54719c7e241ffe0ad4315b808290dbe6c0f              0   \n",
       "\n",
       "                 author                      published  \\\n",
       "0     Barracuda Brigade  2016-10-26T21:41:00.000+03:00   \n",
       "1  reasoning with facts  2016-10-29T08:47:11.259+03:00   \n",
       "2     Barracuda Brigade  2016-10-31T01:41:49.479+02:00   \n",
       "3                Fed Up  2016-11-01T05:22:00.000+02:00   \n",
       "4                Fed Up  2016-11-01T21:56:00.000+02:00   \n",
       "\n",
       "                                               title  \\\n",
       "0  Muslims BUSTED: They Stole Millions In Gov’t B...   \n",
       "1  Re: Why Did Attorney General Loretta Lynch Ple...   \n",
       "2  BREAKING: Weiner Cooperating With FBI On Hilla...   \n",
       "3  PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...   \n",
       "4  FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...   \n",
       "\n",
       "                                                text language  \\\n",
       "0  Print They should pay all the back all the mon...  english   \n",
       "1  Why Did Attorney General Loretta Lynch Plead T...  english   \n",
       "2  Red State : \\nFox News Sunday reported this mo...  english   \n",
       "3  Email Kayla Mueller was a prisoner and torture...  english   \n",
       "4  Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...  english   \n",
       "\n",
       "                         crawled             site_url country  domain_rank  \\\n",
       "0  2016-10-27T01:49:27.168+03:00  100percentfedup.com      US      25689.0   \n",
       "1  2016-10-29T08:47:11.259+03:00  100percentfedup.com      US      25689.0   \n",
       "2  2016-10-31T01:41:49.479+02:00  100percentfedup.com      US      25689.0   \n",
       "3  2016-11-01T15:46:26.304+02:00  100percentfedup.com      US      25689.0   \n",
       "4  2016-11-01T23:59:42.266+02:00  100percentfedup.com      US      25689.0   \n",
       "\n",
       "                                        thread_title  spam_score  \\\n",
       "0  Muslims BUSTED: They Stole Millions In Gov’t B...       0.000   \n",
       "1  Re: Why Did Attorney General Loretta Lynch Ple...       0.000   \n",
       "2  BREAKING: Weiner Cooperating With FBI On Hilla...       0.000   \n",
       "3  PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...       0.068   \n",
       "4  FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...       0.865   \n",
       "\n",
       "                                        main_img_url  replies_count  \\\n",
       "0  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
       "1  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
       "2  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
       "3  http://100percentfedup.com/wp-content/uploads/...              0   \n",
       "4  http://100percentfedup.com/wp-content/uploads/...              0   \n",
       "\n",
       "   participants_count  likes  comments  shares  type  \n",
       "0                   1      0         0       0  bias  \n",
       "1                   1      0         0       0  bias  \n",
       "2                   1      0         0       0  bias  \n",
       "3                   0      0         0       0  bias  \n",
       "4                   0      0         0       0  bias  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/fake.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = df['text']\n",
    "texts = [ i for i in texts ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Print They should pay all the back all the mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Red State : \\nFox News Sunday reported this mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Email Kayla Mueller was a prisoner and torture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts\n",
       "0  Print They should pay all the back all the mon...\n",
       "1  Why Did Attorney General Loretta Lynch Plead T...\n",
       "2  Red State : \\nFox News Sunday reported this mo...\n",
       "3  Email Kayla Mueller was a prisoner and torture...\n",
       "4  Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(texts)\n",
    "df = df.rename(columns={0: 'texts'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['texts'] = df['texts'].str.replace('\\d+', ' ')\n",
    "df['texts'] = df['texts'].str.replace('[^a-zA-Z]+', ' ')\n",
    "df['texts'] = df['texts'].str.findall('\\w{3,}').str.join(' ')\n",
    "df.to_csv(\"finaltexts.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Print They should pay all the back all the mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Red State Fox News Sunday reported this mornin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Email Kayla Mueller was prisoner and tortured ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Email HEALTHCARE REFORM MAKE AMERICA GREAT AGA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts\n",
       "0  Print They should pay all the back all the mon...\n",
       "1  Why Did Attorney General Loretta Lynch Plead T...\n",
       "2  Red State Fox News Sunday reported this mornin...\n",
       "3  Email Kayla Mueller was prisoner and tortured ...\n",
       "4  Email HEALTHCARE REFORM MAKE AMERICA GREAT AGA..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "openfile = open('data/finaltexts1.csv', 'rb')\n",
    "\n",
    "texts = csv.reader(openfile)\n",
    "texts = [x for y in texts for x in y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/linlyn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/linlyn/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ti = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize\n",
    "texts = [[word for word in text.lower().split() ] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lmtzr = WordNetLemmatizer()\n",
    "texts = [[lmtzr.lemmatize(word) for word in text ] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stoplist = stopwords.words('english')\n",
    "texts = [[word for word in text if word not in stoplist] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove short words\n",
    "texts = [[ word for word in tokens if len(word) >= 3 ] for tokens in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A list of extra stopwords specific to the debates transcripts (if you want to remove more stopwords)\n",
    "extra_stopwords = ['will', 'people', 'need', 'think', 'well','going', 'can', 'country', 'know', 'lot', 'get','make','way','president', 'want',\n",
    "                'like','say','got','said','just','something','tell','put','now', 'bad','back','want','right','every','one','use','come','never', \n",
    "                'many','along','things','day','also','first','guy', 'great', 'take', 'good', 'much','anderson', 'let', 'would', 'year', 'thing', 'america',\n",
    "                'talk', 'talking', 'thank', 'does', 'give', 'look', 'believe', 'tonight','today','see','that', 'this', 'em', 'wa', 'http', 'com', 'que','one',\n",
    "                  'want', 'would', 'also']\n",
    "\n",
    "extra_stoplist = extra_stopwords\n",
    "texts = [[word for word in text if word not in extra_stoplist] for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is text processing required for topic modeling with Gensim\n",
    "## Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(texts)\n",
    "\n",
    "## Remove rare and common tokens.\n",
    "# ignore words that appear in less than 5 documents or more than 50% documents (remove too frequent & infrequent words) - an optional step\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5) \n",
    "# convert words to vetors or integers\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 29705\n",
      "Number of documents: 12776\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.wrappers import LdaVowpalWabbit, LdaMallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "numpy.random.seed(1) # setting random seed to get the same results each time. \n",
    "model = ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=35, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "# print words without probability\n",
    "for i in range(0,35):\n",
    "    topics = model.show_topic(i, 10)\n",
    "    print ','.join([str(word[0]) for word in topics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "israel,der,die,jewish,palestinian,jew,israeli,und,den,von\n",
      "text,comment,result,please,name,link,post,email,strong,block\n",
      "area,india,water,time,new,plant,marijuana,technology,chinese,two\n",
      "time,light,life,around,new,man,men,film,eddie,old\n",
      "state,government,american,job,tax,percent,obamacare,new,economy,work\n",
      "russia,russian,war,putin,state,nuclear,military,nato,china,world\n",
      "change,energy,climate,global,solar,power,lukewearechange,earth,could,gas\n",
      "election,vote,voter,state,voting,poll,republican,party,candidate,democrat\n",
      "church,god,christian,south,jesus,north,africa,catholic,ancient,christ\n",
      "air,aircraft,plane,force,general,ship,navy,retired,defense,military\n",
      "government,power,world,political,state,war,even,american,nation,public\n",
      "www,news,infowars,org,video,content,utm,force,twitter,brain\n",
      "child,woman,school,family,student,life,old,parent,death,girl\n",
      "email,medium,podesta,information,news,post,facebook,campaign,source,wikileaks\n",
      "bank,money,million,company,dollar,financial,billion,business,foundation,fund\n",
      "alien,earth,moon,space,star,object,mar,planet,nasa,scientist\n",
      "world,life,human,mind,energy,time,others,power,self,reality\n",
      "clinton,hillary,campaign,bill,democratic,video,wikileaks,election,email,medium\n",
      "time,even,really,could,story,actually,video,still,sure,little\n",
      "law,court,state,case,federal,judge,justice,government,crime,legal\n",
      "police,officer,video,shot,man,gun,twitter,cop,report,shooting\n",
      "soros,trump,protest,border,election,immigrant,george,american,illegal,violence\n",
      "del,los,por,con,para,una,como,dans,pour,par\n",
      "pipeline,dakota,water,access,standing,rock,north,protester,veteran,law\n",
      "city,water,camp,refugee,migrant,local,town,home,october,resident\n",
      "drug,government,french,zone,fly,time,france,medium,dos,war\n",
      "white,black,muslim,american,woman,anti,group,racist,men,community\n",
      "brock,bir,burr,nda,het,weld,tip,det,ndan,nie\n",
      "gold,market,price,stock,silver,rate,world,month,percent,currency\n",
      "clinton,fbi,email,investigation,comey,hillary,department,server,director,new\n",
      "war,obama,house,american,administration,bush,state,washington,policy,secretary\n",
      "obama,assange,state,barack,julian,hillary,john,isi,michelle,email\n",
      "syria,syrian,war,saudi,terrorist,force,isi,government,attack,iraq\n",
      "food,health,study,cancer,disease,body,found,may,water,effect\n",
      "trump,donald,election,hillary,american,republican,win,clinton,candidate,medium\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Assign the topics to documents in corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "lda_corpus = model[corpus]\n",
    "\n",
    "results = []\n",
    "for i in lda_corpus:\n",
    "    print i\n",
    "    results.append(i)\n",
    "print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finding highest value from each row\n",
    "toptopic = [max(collection, key=lambda x: x[1])[0] for collection in results]\n",
    "toptopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Print They should pay all the back all the mon...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Red State Fox News Sunday reported this mornin...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Email Kayla Mueller was prisoner and tortured ...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Email HEALTHCARE REFORM MAKE AMERICA GREAT AGA...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           documents   0\n",
       "0  Print They should pay all the back all the mon...  14\n",
       "1  Why Did Attorney General Loretta Lynch Plead T...  29\n",
       "2  Red State Fox News Sunday reported this mornin...  29\n",
       "3  Email Kayla Mueller was prisoner and tortured ...  34\n",
       "4  Email HEALTHCARE REFORM MAKE AMERICA GREAT AGA...   4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toptopic = pd.DataFrame(toptopic)\n",
    "documents = pd.DataFrame(ti)\n",
    "documents = documents.rename(columns = {0: 'documents'})\n",
    "summary = documents.join(toptopic)\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install pyldavis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8db5c5befce2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(model, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get_term_topic***\n",
    "**return the particular word in particular topic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0.037090503691967168)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_term_topics('russia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(23, 0.011302869989055716), (24, 0.01416806982657581)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_term_topics('water')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 0.012053911413404162),\n",
       " (19, 0.011079433012419811),\n",
       " (25, 0.018079282002055757)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_term_topics('government')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get_document_topics (Predictive Analytics)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(15446, 1), (16530, 1), (28332, 1), (28382, 1)]\n"
     ]
    }
   ],
   "source": [
    "bow = ['russia','government','trump','water']\n",
    "bow = model.id2word.doc2bow(bow) # convert to bag of words format first\n",
    "print bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15446, [5]), (16530, [5, 24]), (28332, [24]), (28382, [34])]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topics, word_topics, phi_values = model.get_document_topics(bow, per_word_topics=True)\n",
    "word_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15446, [(5, 0.99999999999999989)]),\n",
       " (16530, [(5, 0.85819831705572613), (24, 0.14022281257707955)]),\n",
       " (28332, [(24, 0.99999999999999911)]),\n",
       " (28382, [(34, 0.99999999999999967)])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k, v in dictionary.token2id.iteritems():\n",
    "    print k, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unlabeled = [\"The Water is one of the energy in the world\",\n",
    "            \"hillary clinton email server about america election, and the russia president congraduated to the new president of ammerica\",\n",
    "            \"The russia election is not total selected by the russian, it is already sellected\",\n",
    "            \"The terrorist is one of the challenges in the world, which will hurt the relationship between countries, and it also challenge human beens' life\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove useless numbers and alphanumerical words\n",
    "unlabeled = [re.sub(\"[^a-zA-Z]+\", \" \", text) for text in unlabeled]\n",
    "# tokenize\n",
    "unlabeled = [[word for word in text.lower().split() ] for text in unlabeled]\n",
    "# stemming words: having --> have; friends --> friend\n",
    "lmtzr = WordNetLemmatizer()\n",
    "unlabeled = [[lmtzr.lemmatize(word) for word in text ] for text in unlabeled]\n",
    "# remove common words \n",
    "stoplist = stopwords.words('english')\n",
    "unlabeled = [[word for word in text if word not in stoplist] for text in unlabeled]\n",
    "#remove short words\n",
    "unlabeled = [[ word for word in tokens if len(word) >= 3 ] for tokens in unlabeled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 0.75714285714285678)]\n",
      "[(5, 0.13941873499858237), (29, 0.74272412214427441)]\n",
      "[(5, 0.35673361995955233), (7, 0.50857250248942731)]\n",
      "[(4, 0.13958111730626532), (16, 0.63977724896271437), (32, 0.11905433214371842)]\n"
     ]
    }
   ],
   "source": [
    "for i in unlabeled:\n",
    "    bow = model.id2word.doc2bow(i)\n",
    "    doc_topics, word_topics, phi_values = model.get_document_topics(bow, per_word_topics=True)\n",
    "    print doc_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Other Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import LancasterStemmer\n",
    "import sklearn\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# feature engineering (words to vectors)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# classification algorithms (or classifiers)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "# build a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# for gridsearch ... buiild many models with different parameters (e.g., with/without bi-gram)\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# model evaluation, validation\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import lsimodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clinton,trump,state,hillary,obama,american,time,new,war,government\n",
      "clinton,trump,hillary,war,email,government,election,world,fbi,donald\n",
      "trump,clinton,email,donald,fbi,obama,hillary,investigation,white,vote\n",
      "obama,trump,white,house,new,obamacare,donald,administration,war,time\n",
      "russia,war,syria,russian,military,syrian,time,force,nuclear,trump\n",
      "infowars,force,utm,brain,retired,general,life,www,content,admiral\n",
      "retired,general,infowars,utm,admiral,navy,air,brain,rear,major\n",
      "del,los,por,con,para,gold,una,bank,como,hija\n",
      "gold,del,state,bank,money,government,debt,los,por,syria\n",
      "state,russia,gold,russian,election,law,vote,american,government,world\n",
      "fbi,clinton,election,russia,russian,comey,investigation,email,war,hillary\n",
      "election,government,russia,trump,vote,syria,fbi,syrian,voter,party\n",
      "state,election,war,russia,syria,party,white,united,trump,gold\n",
      "fbi,world,syria,comey,war,email,syrian,american,water,jewish\n",
      "gold,jewish,black,american,israel,state,police,jew,russia,arab\n",
      "gold,black,jewish,jew,government,white,police,war,pipeline,israel\n",
      "die,der,und,den,von,gold,mit,war,ist,auf\n",
      "hillary,jewish,die,der,gold,vaccine,jew,und,war,police\n",
      "hillary,russia,government,russian,energy,god,clinton,new,money,war\n",
      "war,vaccine,nuclear,gold,hillary,syria,syrian,child,woman,consciousness\n",
      "black,state,white,water,pipeline,gold,jewish,dakota,child,hillary\n",
      "medium,hillary,gold,nuclear,war,could,clinton,vaccine,world,news\n",
      "hillary,american,food,fbi,water,black,time,syria,clinton,comey\n",
      "time,gold,law,hillary,american,clinton,police,party,news,vaccine\n",
      "american,hillary,black,gold,nuclear,bank,white,god,clinton,pipeline\n",
      "woman,black,white,party,jewish,government,political,new,consciousness,muslim\n",
      "vaccine,world,zika,hillary,american,law,body,pipeline,gold,light\n",
      "email,american,police,podesta,woman,new,bank,party,state,black\n",
      "woman,email,campaign,podesta,world,bank,party,white,clinton,war\n",
      "lesley,stahl,donald,trump,election,email,kenya,african,line,child\n",
      "woman,government,vaccine,party,israel,nuclear,men,god,law,hillary\n",
      "american,nuclear,war,vaccine,email,force,lesley,stahl,israel,military\n",
      "god,government,christian,church,jesus,article,email,police,black,american\n",
      "war,government,child,power,email,zika,gold,woman,new,consciousness\n",
      "new,party,nuclear,kenya,vaccine,election,article,government,police,world\n"
     ]
    }
   ],
   "source": [
    "lsi = lsimodel.LsiModel(corpus, id2word=dictionary, num_topics=35)\n",
    "for i in range(0,35):\n",
    "    topics = lsi.show_topic(i, 10)\n",
    "    print ','.join([str(word[0]) for word in topics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn import decomposition\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "n_topics = 35\n",
    "n_features = 20\n",
    "n_top_words = 10\n",
    "\n",
    "texts = [str(i) for i in texts]\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(texts)\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=n_features,stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(texts)\n",
    "\n",
    "\n",
    "\n",
    "nmf = NMF(n_components=n_topics, random_state=1, alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "people ha world time wa government like year american right\n",
      "Topic #1:\n",
      "weiner abedin email huma anthony fbi laptop investigation device clinton\n",
      "Topic #2:\n",
      "trump donald republican president campaign supporter election ha win american\n",
      "Topic #3:\n",
      "russia russian putin nato moscow vladimir ukraine military said relation\n",
      "Topic #4:\n",
      "text result italic block automatically bold comment strong formating blockquote\n",
      "Topic #5:\n",
      "fbi comey investigation email director letter james clinton election server\n",
      "Topic #6:\n",
      "pravda fotodom reuters bild afp xiii national kremlin whatsapp volkswagen\n",
      "Topic #7:\n",
      "bundy federal ammon jury oregon refuge defendant standoff verdict malheur\n",
      "Topic #8:\n",
      "election vote voting voter ballot machine fraud state electoral republican\n",
      "Topic #9:\n",
      "http com www youtube utm infowars twitter wearechange watch gmt\n",
      "Topic #10:\n",
      "que los del por la para una como est sus\n",
      "Topic #11:\n",
      "pipeline dakota water rock standing protester police protector sioux north\n",
      "Topic #12:\n",
      "gold market silver price stock dollar bank currency metal kwn\n",
      "Topic #13:\n",
      "obama president white house administration obamacare barack democrat michelle american\n",
      "Topic #14:\n",
      "facebook conversation comment add using source account disqus article follow\n",
      "Topic #15:\n",
      "wa police woman said officer child man old year video\n",
      "Topic #16:\n",
      "der die und da den von auf sich mit ist\n",
      "Topic #17:\n",
      "podesta email wikileaks campaign assange john kadzik clinton released server\n",
      "Topic #18:\n",
      "email notify post subscribe blog donate address donation new follow\n",
      "Topic #19:\n",
      "israel palestinian israeli jewish jerusalem resolution unesco jew netanyahu palestine\n",
      "Topic #20:\n",
      "stockman david contrarian daily contra adler corner curated banditry november\n",
      "Topic #21:\n",
      "galacticconnection click com galactic alexandra mail psychic address newsletter permission\n",
      "Topic #22:\n",
      "vaccine cancer health food study drug disease medical doctor vitamin\n",
      "Topic #23:\n",
      "mosul iraqi isi force iraq city daesh turkey kurdish civilian\n",
      "Topic #24:\n",
      "black white african police people racist community racism american democrat\n",
      "Topic #25:\n",
      "hillary clinton vote woman october video medium rally supporter twitter\n",
      "Topic #26:\n",
      "aleppo syrian syria civilian rebel terrorist qaeda russian attack assad\n",
      "Topic #27:\n",
      "saudi arabia yemen yemeni qatar kingdom houthi riyadh arm isi\n",
      "Topic #28:\n",
      "war syria nuclear russia military iraq iran china state policy\n",
      "Topic #29:\n",
      "clinton foundation hillary campaign wa democratic band secretary state presidential\n",
      "Topic #30:\n",
      "percent poll voter point lead republican polling democrat survey support\n",
      "Topic #31:\n",
      "cleveland turtle american reminding eaten hatch thursday cursed bird specie\n",
      "Topic #32:\n",
      "veteran arnaldo rodgers vnn view entry response post author trackback\n",
      "Topic #33:\n",
      "godlike glp godlikeproductions trademark query page generated registered copyright production\n",
      "Topic #34:\n",
      "guest ticker nov story posted click article duke apepper account\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
